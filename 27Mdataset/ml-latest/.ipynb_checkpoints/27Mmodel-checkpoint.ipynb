{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read ratings data\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_user_num = max(ratings['userId'])\n",
    "print(max_user_num)\n",
    "max_movie_id = max(ratings['movieId'])\n",
    "print(max_movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies.csv')\n",
    "movieIndex = range(0, movies.shape[0])\n",
    "movies['movieIndex'] = movieIndex\n",
    "movies.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('links.csv')\n",
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['imdbId'] = links['imdbId'][movies['movieId'] == links['movieId']]\n",
    "movies['tmdbId'] = links['tmdbId'][movies['movieId'] == links['movieId']]\n",
    "movies.to_csv('movies-indexed.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_ratings = pd.read_csv('indexed-movie-rating.csv')\n",
    "indexed_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_ratings = indexed_ratings.drop(['Selected', 'Selected.1', 'Selected (1)'], axis=1)\n",
    "indexed_ratings['userId'] = indexed_ratings['userId'].astype(int)\n",
    "indexed_ratings['movieId'] = indexed_ratings['movieId'].astype(int)\n",
    "indexed_ratings['movieIndex'] = indexed_ratings['movieIndex'].astype(int)\n",
    "indexed_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_movie_index = int(max(indexed_ratings['movieIndex']))\n",
    "rating_matrix = []\n",
    "print(max_movie_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get values of genres\n",
    "unique_genre = movies['genres'].unique()\n",
    "genre_values = []\n",
    "for movie_genre in unique_genre:\n",
    "    mg = movie_genre.split(\"|\")\n",
    "    for g in mg:\n",
    "        if g not in genre_values:\n",
    "            genre_values.append(g)\n",
    "            \n",
    "genre_values = sorted(genre_values, key=str.lower)\n",
    "\n",
    "print(genre_values)\n",
    "print(len(genre_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_scores = pd.read_csv('indexed-movie-genome-scores.csv')\n",
    "print(genome_scores.shape)\n",
    "genome_scores['movieId'] = genome_scores['movieId'].astype(int)\n",
    "genome_scores['tagId'] = genome_scores['tagId'].astype(int)\n",
    "genome_scores['movieIndex'] = genome_scores['movieIndex'].astype(int)\n",
    "genome_scores = genome_scores.drop(['Selected'], axis=1)\n",
    "genome_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique values of genome tags\n",
    "print(genome_scores['tagId'].unique())\n",
    "print(genome_scores['tagId'].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get genre vector\n",
    "def get_genre_vector(genre_row_val):\n",
    "    mg = genre_row_val.split(\"|\")\n",
    "    gen_vec = np.zeros(len(genre_values))\n",
    "    gen_index = 0\n",
    "    for g in genre_values:\n",
    "        if g in mg:\n",
    "            gen_vec[gen_index] = 1\n",
    "        gen_index += 1\n",
    "\n",
    "    return gen_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get genome vector\n",
    "def get_genome_vector(movieIndex):\n",
    "    return genome_scores['relevance'][genome_scores['movieIndex'] == movieIndex].tolist()\n",
    "\n",
    "print(len(get_genome_vector(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add genre vector\n",
    "movie_data = movies['genres']\n",
    "movie_genre_col = []\n",
    "movie_genome_col = []\n",
    "gen_index = 0\n",
    "for movie_gen in movie_data:\n",
    "    gen_vec = get_genre_vector(movie_gen)\n",
    "    movie_genre_col.append(gen_vec)\n",
    "    gen_index += 1\n",
    "    \n",
    "for movieIndex in movies['movieIndex']:\n",
    "    if movieIndex % 1000 == 0:\n",
    "        print(movieIndex)\n",
    "    movie_genome_col.append(get_genome_vector(movieIndex))\n",
    "    \n",
    "    \n",
    "movies['genre_vector'] = movie_genre_col\n",
    "movies['genome_vector'] = movie_genome_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove commented code for full model\n",
    "def add_genre_genome_tag_vectors(data):\n",
    "    genre_array = []\n",
    "    genome_array = []\n",
    "    movie_index_list = data['movieIndex'].astype(int).tolist()\n",
    "    index = 0\n",
    "    for movie_index in movie_index_list:\n",
    "        if index % 10000 == 0:\n",
    "            print('====>')\n",
    "            print(index)\n",
    "        index = index + 1\n",
    "        #genre_array.append(np.array(movies['genre_vector'][movies['movieIndex'] == movie_index].tolist()[0]))\n",
    "        #genome_array.append(np.array(movies['genome_vector'][movies['movieIndex'] == movie_index].tolist()[0]))\n",
    "    #data['genre_vector'] = genre_array\n",
    "    #data['genome_vector'] = genome_array\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(movies['genre_vector'][movies['movieIndex'] == 1].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexed_ratings = add_genre_genome_tag_vectors(indexed_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1000\n",
    "for user in range(1, max_user_num, step):\n",
    "    print('---->')\n",
    "    print(user)\n",
    "    selected_ratings = indexed_ratings[(indexed_ratings['userId'] >= user) & \n",
    "                                       (indexed_ratings['userId'] <= user + step)]\n",
    "    print('shape:')\n",
    "    print(selected_ratings.shape)\n",
    "    selected_ratings = add_genre_genome_tag_vectors(selected_ratings)\n",
    "    selected_ratings.to_pickle('split_data/ratings_batch'+str(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rat = pd.read_pickle('split_data/ratings_batch1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_genre_sum = np.zeros(len(genre_values))\n",
    "#user_genre_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(rat['genre_vector'][0])+user_genre_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(max_movie_index+1+len(genre_values)+genome_scores['tagId'].unique().shape[0], 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, max_movie_index+1+len(genre_values)+genome_scores['tagId'].unique().shape[0])\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a neural network instance\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in loop for everyfile\n",
    "user = 1\n",
    "ratings = pd.read_csv('split_data/ratings_batch'+str(user)+'.csv')\n",
    "ratings = ratings.drop(['Unnamed: 0', 'timestamp'], axis=1)\n",
    "ratings['movieIndex'] = ratings['movieIndex'].astype(int)\n",
    "ratings['userId'] = ratings['userId'].astype(int)\n",
    "ratings['movieId'] = ratings['movieId'].astype(int)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in loop for everyfile\n",
    "rating_matrix = []\n",
    "for user in ratings['userId'].unique():\n",
    "    # user rating columns\n",
    "    user_rating_data = np.zeros(max_movie_index+1)\n",
    "    user_rating_data[ratings['movieIndex'][ratings['userId'] == user]] = ratings['rating'][ratings['userId'] == user]\n",
    "    # user genre columns\n",
    "    user_genre_list = ratings['genre_vector'][ratings['userId'] == user][ratings['rating'] >= 3]\n",
    "    user_genre_sum = np.zeros(len(genre_values))\n",
    "    for usr_gen_vec in user_genre_list:\n",
    "        if len(usr_gen_vec):\n",
    "            user_genre_sum = user_genre_sum + np.array(usr_gen_vec)\n",
    "    # Add columns of user genre only for good ratings\n",
    "    if user_genre_sum[0].shape:\n",
    "        data_reshaped = np.append(user_rating_data, user_genre_sum[0])\n",
    "    else:\n",
    "        data_reshaped = np.append(user_rating_data, user_genre_sum)\n",
    "    # genome tag columns\n",
    "    user_genome_list = ratings['genome_vector'][ratings['userId'] == user][ratings['rating'] >= 3]\n",
    "    user_genome_sum = np.zeros(genome_scores['tagId'].unique().shape[0])\n",
    "    for usr_genome_vec in user_genome_list:\n",
    "        if len(usr_genome_vec):\n",
    "            user_genome_sum = user_genome_sum + np.array(usr_genome_vec)\n",
    "    if user_genome_sum[0].shape:\n",
    "        data_reshaped = np.append(data_reshaped, user_genome_sum[0])\n",
    "    else:\n",
    "        data_reshaped = np.append(data_reshaped, user_genome_sum)\n",
    "   \n",
    "    rating_matrix.append(list(data_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in loop for everyfile\n",
    "# split data in training and testing sets\n",
    "\n",
    "num_users = len(rating_matrix)\n",
    "print('num_users')\n",
    "print(num_users)\n",
    "training_set_num = int(0.8 * num_users)\n",
    "print('training_set_num')\n",
    "print(training_set_num)\n",
    "testing_set_num = int(num_users) - training_set_num\n",
    "print('testing_set_num')\n",
    "print(testing_set_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in loop for everyfile\n",
    "# split data in training and testing sets\n",
    "training_set = rating_matrix[:training_set_num]\n",
    "testing_set = rating_matrix[training_set_num:]\n",
    "print(len(training_set))\n",
    "print(len(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in loop for everyfile\n",
    "# create torch tensors\n",
    "training_set_torch = torch.FloatTensor(training_set)\n",
    "test_set_torch  = torch.FloatTensor(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in loop for everyfile\n",
    "# train the neural network\n",
    "nb_epoch = 5\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(len(training_set)):\n",
    "        input = Variable(training_set_torch[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = (max_movie_index+1)/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data[0]*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "    \n",
    "    \n",
    "# Testing the SAE\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(len(testing_set)):\n",
    "    input = Variable(test_set_torch[id_user]).unsqueeze(0)\n",
    "    target = Variable(test_set_torch[id_user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = (max_movie_index+1)/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data[0]*mean_corrector)\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
